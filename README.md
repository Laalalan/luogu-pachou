| 这个作业属于哪个课程 | [2023年秋 - 福州大学软件工程](https://bbs.csdn.net/forums/fzusdn-0831) |
| ----------------- |--------------- |
| 这个作业要求在哪里| [2023秋软工实践个人作业一](https://bbs.csdn.net/topics/617176123) |
| 这个作业的目标 | 1.掌握pyhton语言 2.了解爬虫过程 3.tkinter GUI设计 4.copliot和ChatGPT使用 |
| 学号 | 102299105 |

# 背景
为了更好地提升代码能力，jason哥想要收集相应的题目，有针对性地刷题。而需要收集洛谷所有题目，但是工作量太大，所以jason哥急需大家运用爬虫技术，得到洛谷各种难度的题目和题解。考虑到近来流行的AIGC技术，jason哥认为，在AI的帮助下，这项工作的难度会大大降低。
# 项目要求
在AIGC技术的帮助下，利用Copilot等工具，运用Python完成爬虫，并用Tkinter库制作相应的GUI页面，将爬取到的题目以markdown文件存储，放到相应文件夹下。

# [ github仓库](https://github.com/Laalalan/luogu-pachou)

# 前端页面

![img](https://img-community.csdnimg.cn/images/e5771870d0114125acb4b6d46bd9244a.png "#left")

Tkinter库制作相应的GUI页面

![img](https://img-community.csdnimg.cn/images/1e536a6a35a845b3922507441f84388b.png "#left")

Vue页面截图的 （待完成）

# 附加分：

以图表（或其他形式）显示实时爬取情况，如吞吐量等（待完成）

以视频/plog等形式记录使用AIGC工具的过程 

![img](https://img-community.csdnimg.cn/images/7cbd1370349547f3bb02804f156eaab1.png "#left")

![img](https://img-community.csdnimg.cn/images/9ea2383dc6c043949821fdf7e5bd1246.png "#left")
# AIGC表格：

爬虫任务可以被分解成哪几个小任务？预估哪几个子任务可以利用AIGC？实际中哪些部分利用了AIGC？

|  子任务   | 预估哪些部分使用AIGC | 实际中哪些部分使用AIGC |
|--|--|--  |
| 爬取题目内容 | 伪装heards，发送请求获取源码 | 可以用来调整报错，开始框架需要自己搭建 |
| 爬取题目题解 | 获取网页源码，定位题目题解 | 可以用来调整报错 |
| 爬取题目标签和难度 | 获取网页源码，定位题目标签和难度 | 可以用来调整报错 |
| GUI可视化 |  tkinter窗口生成 | ✔ |
| html搭建 | 生成基础页面 | ✔ |
| 测试用例 | 生成具体内容 | ✔ |
| 获取copilot | 取得GitHub学生认证 | 成功但是用不了，用的chatgpt的端口 |

优点：

1、可以马上识别报错类型
2、可以生成大量高质量的文本内容，帮助人们迅速获得所需信息。
3、AIGC技术可以快速产生响应，为用户提供实时解答和建议。
4、可以解决简单代码基础问题

缺点：

1、钉是钉铆是铆，没有创造力。根据输入生成对应输出，缺乏主动提问和深入理解的能力，可能无法准确把握用户意图。
2、给出的解决方案不一定适用，可能只是花架子。会受到训练数据的偏见影响，生成带有错误或不准确信息的文本。
3、缺乏与人类相似的直觉和判断能力，可能会生成不合逻辑或不合理的内容。

# 总结	 	 

通过爬虫洛谷，我学习到以下内容：

1、爬虫技术：通过爬虫洛谷，学习如何使用编程语言（如Python）和相关的爬虫库（如BeautifulSoup、Scrapy等）来获取网页内容。学会l使用HTTP请求发送和接收数据，解析HTML文档，提取所需信息等。

2、数据获取和处理：通过爬虫洛谷，我可以获取洛谷上的题目、提交记录、用户信息等数据。你可以学会如何从网页中提取结构化数据，并进行相应的处理和分析。

**心得体会：**

软工真的真的很有挑战性ㄒ-ㄒ（不是所有的挑战都会成功的）。因为二学位基础比较差（其实就是全短板，桶中没有几两水），一开始根本不知道从哪里下手，开始做了事情也还是惊人的毫无变化，一个报错后有另一个报错，304解决了以后还有402，200是成功是但是数据没有爬取。就连大家都很顺利的thinker搭建也一团糟，爬出来的数据没有按难度分类建立文件（周五截止时间到了，又不死心的弄了一晚上）。AI也很不顺利，copilot学生认证approved了，但还是不能用。chatgpt梯子的ip号都被封了，courser安装倒是很顺利但是也用不了。只能用国内接口的chat，只能说蠢钝如猪（难用的要命）。怎么说呢，要想解决问题还得是靠自己扎扎实实的去学有关知识，AI只是工具，它可以帮我们润色，但没有办法帮助我们创造。锦上添花需要它，从无到有还是需要自己。

待完成：

1、Vue界面搭建（组件导入了还是没法调用，需要整理一下），前后端连接（不会，要学）

2、标签爬取并保存，显示实时爬取，GUI界面crawl数据导入

# PSP表格（放Github）

| 子任务             | 预估用时 | 实际用时                                  |
| ------------------ | -------- | ----------------------------------------- |
| 学习python         | 3h       | 差不多，简单了解                          |
| 爬取题目题解       | 3h       | 6h                                        |
| 爬取题目标签和难度 | 3h       | 6h+，在报错地狱里根本没完成               |
| tkinter窗口生成    | 0.5h     | 2h，调整过程Chat突然发疯                  |
| html搭建           | 2h       | 4h，Vue不知道导入组件库后样式一点都不显示 |
| 测试用例           | 2h       | 没来得及做                                |
| 获取copilot        | 1h       | 5h，学生认证超麻烦，虽然成功但是用不了    |
